#!/usr/bin/env python
# coding: utf-8



import csv
import networkx as nx 
import pprint as pp
import itertools
from tabulate import tabulate



def create_graph(book_number): 
    path = "/Users/yves/Desktop/DMT_2020/HW_2/DMT_2020__HW_2/Part_2/dataset/book_"+str(book_number)+".tsv"
    input_file = open(path, 'r', encoding= 'utf8')
    tsv_reader = csv.reader(input_file, delimiter = '\t')

    #### Create a Graph
    list_of_names = []
    for name in tsv_reader:
        u = name[0]
        v = name[1]
        list_of_names.append((u,v))
    input_file.close()

    graph = nx.Graph()
    graph.add_edges_from(list_of_names)

    #print("Number of nodes in the graph "+str(book_number)+": ", graph.number_of_nodes())
    #print("Number of edges in the graph "+str(book_number)+": ", graph.number_of_edges())
    
    return graph



damping_factor = [0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05]


exponent = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]


combo = list(itertools.product(damping_factor, exponent))



def compute_good_local_community(graph, seed_node_id, alpha, exponent): # alpha is the dumping factor
    #
    # Creation of the teleporting probability distribution for the selected node...
    map_teleporting_probability_distribution__node_id__probability = {}
    for node_id in graph:
        map_teleporting_probability_distribution__node_id__probability[node_id] = 0.
    map_teleporting_probability_distribution__node_id__probability[seed_node_id] = 1.
    #
    # Computation of the PageRank vector.
    map__node_id__node_pagerank_value = nx.pagerank(graph, alpha=alpha,
                                                    personalization=map_teleporting_probability_distribution__node_id__probability, weight='weight')
    #
    # Put all nodes in a list and sort the list in descending order of the â€œnormalized_scoreâ€.
    sorted_list__node_id__normalized_score = [(node_id, score / (graph.degree[node_id])**exponent)
                                              for node_id, score in map__node_id__node_pagerank_value.items()]
    sorted_list__node_id__normalized_score.sort(key=lambda x: (-x[1], x[0]))
    #
    # LET'S SWEEP!
    index_representing_the_set_of_node_ids_with_maximum_conductance = -1
    min_conductance_value = float("+inf")
    set__node_ids_in_the_candidate_community = set()
    set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes = set(graph.nodes())
    for sweep_index in range(0, len(sorted_list__node_id__normalized_score) - 1):
        #
        # Creation of the set of nodes representing the candidate community and
        # its complement to the entire set of nodes in the graph.
        current_node_id = sorted_list__node_id__normalized_score[sweep_index][0]
        set__node_ids_in_the_candidate_community.add(current_node_id)
        set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes.remove(current_node_id)
        #
        # Evaluation of the quality of the candidate community according to its conductance value.
        conductance_value = nx.algorithms.cuts.conductance(graph,
                                                           set__node_ids_in_the_candidate_community,
                                                           set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes)
        #
        # Discard local communities with conductance 0 or 1.
        if conductance_value == 0. or conductance_value == 1.:
            continue
        #
        # Update the values of variables representing the best solution generated so far.
        if conductance_value < min_conductance_value:
            min_conductance_value = conductance_value
            index_representing_the_set_of_node_ids_with_maximum_conductance = sweep_index
    #
    # Creation of the set of nodes representing the best local community generated by the sweeping procedure.
    set__node_ids_with_minimum_conductance = set([node_id for node_id, normalized_score in
                                                  sorted_list__node_id__normalized_score[
                                                  :index_representing_the_set_of_node_ids_with_maximum_conductance + 1]])
    #
    return set__node_ids_with_minimum_conductance, min_conductance_value


def computation(G, person, combos = combo):
    characters = []
    scores = []

    for elements in combos:
        deg = elements[0]
        expo = elements[1]
        output = compute_good_local_community(G, person, deg, expo)
        characters.append(output[0])
        scores.append(output[1])
    index = scores.index(min(scores))
    N = len(characters[index])
    C = combos[index]
    S = scores[index]
    
    #print("Best Combination ==>  ", "Damping factor: "+str(C[0]), " |  Exponent: "+str(C[1]))
    #print("Number of characters in community ", N)
    #print("Conductance Value ", S)
    
    return characters[index],C,N,S

books = [1,2,3,4] ## add book 3 and 4
OUT = []
people = ["Daenerys-Targaryen","Jon-Snow","Samwell-Tarly","Tyrion-Lannister"]
for book in books:
    graph = create_graph(book)
    for person in people:
        Result = []
        Result.append("book_"+str(book))  # BOOK NUMBER
        Result.append(person) # CHARACTER
        print("Computation for "+person+" in book number "+str(book))
        Char, C, N, S = computation(graph, person)
        Result.append(C[0]) # DUMPING FACTOR
        Result.append(C[1]) # EXPONENT
        Result.append(round(S,3)) # CONDUCTANCE VALUE
        Baratheon = []
        Lannister = []
        Stark = []
        Targaryen = []
        for ele in Char:
            if "Baratheon" in ele.split("-"):
                Baratheon.append(ele)
            elif "Lannister" in ele.split("-"):
                Lannister.append(ele)
            elif "Stark" in ele.split("-"):
                Stark.append(ele)
            elif "Targaryen" in ele.split("-"):
                Targaryen.append(ele)
        Result.append(len(Baratheon))
        Result.append(len(Lannister))
        Result.append(len(Stark))
        Result.append(len(Targaryen))
        Result.append(N) # NUMBER OF ELEMENTS IN THE COMMUNITY
        OUT.append(Result)
print(tabulate(OUT, headers=["Book","Char", "Dump_Fac", "Expo", "Conduc.", "Barath_Fam", "Lann_Fam", "Sta_Fam", "Targ_Fam", "# Comm."]))

with open('output.tsv', 'w', newline='') as f_output:
    tsv_output = csv.writer(f_output, delimiter='\t')
    tsv_output.writerow(["Book","Character", "Dumping_Factor", "Exponent", "Conductance", "Baratheon_Family", "Lannister_Family", "Stark_Family", "Targaryen_Family", "Number_Characters_In_Comunity"])
    for line in OUT:
        tsv_output.writerow(line)



